import asyncio
import logging
import re
import time
from uuid import uuid4
from datetime import datetime
from typing import Any, Optional
from pathlib import Path

from Undefined.config import Config
from Undefined.faq import FAQStorage, extract_faq_title
from Undefined.onebot import (
    OneBotClient,
    get_message_content,
    get_message_sender_id,
    parse_message_time,
)
from Undefined.utils.sender import MessageSender
from Undefined.services.commands.context import CommandContext
from Undefined.services.commands.registry import CommandMeta, CommandRegistry
from Undefined.services.security import SecurityService
from Undefined.token_usage_storage import TokenUsageStorage

# å°è¯•å¯¼å…¥ matplotlib
plt: Any
try:
    import matplotlib.pyplot as plt

    _MATPLOTLIB_AVAILABLE = True
except ImportError:
    plt = None
    _MATPLOTLIB_AVAILABLE = False

logger = logging.getLogger(__name__)


_STATS_DEFAULT_DAYS = 7
_STATS_MIN_DAYS = 1
_STATS_MAX_DAYS = 365
_STATS_MODEL_TOP_N = 8
_STATS_CALL_TYPE_TOP_N = 12
_STATS_DATA_SUMMARY_MAX_CHARS = 12000


class CommandDispatcher:
    """å‘½ä»¤åˆ†å‘å¤„ç†å™¨ï¼Œè´Ÿè´£è§£æå’Œæ‰§è¡Œæ–œæ å‘½ä»¤"""

    def __init__(
        self,
        config: Config,
        sender: MessageSender,
        ai: Any,  # AIClient
        faq_storage: FAQStorage,
        onebot: OneBotClient,
        security: SecurityService,
        queue_manager: Any = None,
        rate_limiter: Any = None,
    ) -> None:
        """åˆå§‹åŒ–å‘½ä»¤åˆ†å‘å™¨

        å‚æ•°:
            config: å…¨å±€é…ç½®å®ä¾‹
            sender: æ¶ˆæ¯å‘é€åŠ©æ‰‹
            ai: AI å®¢æˆ·ç«¯(ç”¨äºå½’çº³å’Œæ ‡é¢˜ç”Ÿæˆ)
            faq_storage: FAQ å­˜å‚¨ç®¡ç†å™¨
            onebot: OneBot HTTP API å®¢æˆ·ç«¯
            security: å®‰å…¨å®¡è®¡ä¸é™æµæœåŠ¡
            queue_manager: AI è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨
            rate_limiter: é€Ÿç‡é™åˆ¶å™¨
        """
        self.config = config
        self.sender = sender
        self.ai = ai
        self.faq_storage = faq_storage
        self.onebot = onebot
        self.security = security
        self.queue_manager = queue_manager
        self.rate_limiter = rate_limiter
        self._token_usage_storage = TokenUsageStorage()
        # å­˜å‚¨ stats åˆ†æç»“æœï¼Œç”¨äºé˜Ÿåˆ—å›è°ƒ
        self._stats_analysis_results: dict[str, str] = {}
        self._stats_analysis_events: dict[str, asyncio.Event] = {}

        commands_dir = Path(__file__).parent / "commands"
        self.command_registry = CommandRegistry(commands_dir)
        self.command_registry.load_commands()
        logger.info("[å‘½ä»¤] å‘½ä»¤ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ: dir=%s", commands_dir)

    def parse_command(self, text: str) -> Optional[dict[str, Any]]:
        """è§£ææ–œæ å‘½ä»¤å­—ç¬¦ä¸²

        å‚æ•°:
            text: åŸå§‹æ–‡æœ¬å†…å®¹

        è¿”å›:
            åŒ…å«å‘½ä»¤å(name)å’Œå‚æ•°åˆ—è¡¨(args)çš„å­—å…¸ï¼Œè§£æå¤±è´¥åˆ™è¿”å› None
        """
        clean_text = re.sub(r"\[@\s*\d+(?:\(.*?\))?\]", "", text).strip()
        match = re.match(r"/(\w+)\s*(.*)", clean_text)
        if not match:
            return None

        cmd_name = match.group(1).lower()
        args_str = match.group(2).strip()

        logger.debug(
            "[å‘½ä»¤] è§£æå‘½ä»¤: text_len=%s cmd=%s args=%s",
            len(text),
            cmd_name,
            args_str,
        )
        return {
            "name": cmd_name,
            "args": args_str.split() if args_str else [],
        }

    def _parse_time_range(self, time_str: str) -> int:
        """è§£ææ—¶é—´èŒƒå›´å­—ç¬¦ä¸²ï¼Œè¿”å›å¤©æ•°

        å‚æ•°:
            time_str: æ—¶é—´èŒƒå›´å­—ç¬¦ä¸²ï¼ˆå¦‚ "7d", "1w", "30d"ï¼‰

        è¿”å›:
            å¤©æ•°
        """
        if not time_str:
            return _STATS_DEFAULT_DAYS

        def _clamp_days(value: int) -> int:
            if value < _STATS_MIN_DAYS:
                return _STATS_DEFAULT_DAYS
            if value > _STATS_MAX_DAYS:
                return _STATS_MAX_DAYS
            return value

        time_str = time_str.lower().strip()

        # è§£æå¿«æ·æ ¼å¼
        if time_str.endswith("d"):
            try:
                return _clamp_days(int(time_str[:-1]))
            except ValueError:
                return _STATS_DEFAULT_DAYS
        elif time_str.endswith("w"):
            try:
                return _clamp_days(int(time_str[:-1]) * 7)
            except ValueError:
                return _STATS_DEFAULT_DAYS
        elif time_str.endswith("m"):
            try:
                return _clamp_days(int(time_str[:-1]) * 30)
            except ValueError:
                return _STATS_DEFAULT_DAYS

        # å°è¯•ç›´æ¥è§£æä¸ºæ•°å­—ï¼ˆé»˜è®¤ä¸ºå¤©ï¼‰
        try:
            return _clamp_days(int(time_str))
        except ValueError:
            return _STATS_DEFAULT_DAYS

    async def _handle_stats(
        self, group_id: int, sender_id: int, args: list[str]
    ) -> None:
        """å¤„ç† /stats å‘½ä»¤ï¼Œç”Ÿæˆ token ä½¿ç”¨ç»Ÿè®¡å›¾è¡¨å¹¶è¿›è¡Œ AI åˆ†æ"""
        # 1. åŸºç¡€ç¯å¢ƒä¸å‚æ•°æ£€æŸ¥
        if not _MATPLOTLIB_AVAILABLE:
            await self.sender.send_group_message(
                group_id, "âŒ ç¼ºå°‘å¿…è¦çš„åº“ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚è¯·å®‰è£… matplotlibã€‚"
            )
            return

        if args and args[0] == "--help":
            await self._handle_stats_help(group_id)
            return

        days = self._parse_time_range(args[0]) if args else 7

        try:
            # 2. è·å–å¹¶éªŒè¯æ•°æ®
            summary = await self._token_usage_storage.get_summary(days=days)
            if summary["total_calls"] == 0:
                await self.sender.send_group_message(
                    group_id, f"ğŸ“Š æœ€è¿‘ {days} å¤©å†…æ—  Token ä½¿ç”¨è®°å½•ã€‚"
                )
                return

            # 3. ç”Ÿæˆå›¾è¡¨æ–‡ä»¶
            from Undefined.utils.paths import RENDER_CACHE_DIR, ensure_dir

            img_dir = ensure_dir(RENDER_CACHE_DIR)
            await self._generate_line_chart(summary, img_dir, days)
            await self._generate_bar_chart(summary, img_dir)
            await self._generate_pie_chart(summary, img_dir)
            await self._generate_stats_table(summary, img_dir)

            # 4. æŠ•é€’ AI åˆ†æè¯·æ±‚åˆ°é˜Ÿåˆ—
            ai_analysis = ""
            if self.queue_manager:
                # æ„å»ºæ•°æ®æ‘˜è¦
                data_summary = self._build_data_summary(summary, days)

                # åˆ›å»ºäº‹ä»¶ç­‰å¾…åˆ†æç»“æœ
                request_id = uuid4().hex
                analysis_event = asyncio.Event()
                self._stats_analysis_events[request_id] = analysis_event

                # æŠ•é€’åˆ°é˜Ÿåˆ—
                request_data = {
                    "type": "stats_analysis",
                    "group_id": group_id,
                    "request_id": request_id,
                    "sender_id": sender_id,
                    "data_summary": data_summary,
                    "summary": summary,
                    "days": days,
                }
                await self.queue_manager.add_group_mention_request(
                    request_data, model_name=self.config.chat_model.model_name
                )
                logger.info(f"[Stats] å·²æŠ•é€’ AI åˆ†æè¯·æ±‚åˆ°é˜Ÿåˆ—ï¼Œç¾¤: {group_id}")

                # ç­‰å¾… AI åˆ†æç»“æœï¼Œ8åˆ†é’Ÿè¶…æ—¶
                try:
                    await asyncio.wait_for(analysis_event.wait(), timeout=480.0)
                    ai_analysis = self._stats_analysis_results.pop(request_id, "")
                    logger.info(f"[Stats] å·²è·å– AI åˆ†æç»“æœï¼Œé•¿åº¦: {len(ai_analysis)}")
                except asyncio.TimeoutError:
                    logger.warning(f"[Stats] AI åˆ†æè¶…æ—¶ï¼Œç¾¤: {group_id}ï¼Œä»…å‘é€å›¾è¡¨")
                    ai_analysis = "AI åˆ†æè¶…æ—¶ï¼Œå·²å…ˆå‘é€å›¾è¡¨ä¸æ±‡æ€»æ•°æ®ã€‚"
                finally:
                    self._stats_analysis_events.pop(request_id, None)
                    self._stats_analysis_results.pop(request_id, None)

            # 5. æ„å»ºå¹¶å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼ˆåŒ…å« AI åˆ†æï¼‰
            forward_messages = self._build_stats_forward_nodes(
                summary, img_dir, days, ai_analysis
            )
            await self.onebot.send_forward_msg(group_id, forward_messages)

            from Undefined.utils.cache import cleanup_cache_dir

            cleanup_cache_dir(RENDER_CACHE_DIR)

        except Exception as e:
            error_id = uuid4().hex[:8]
            logger.exception(
                "[Stats] ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥: error_id=%s err=%s", error_id, e
            )
            await self.sender.send_group_message(
                group_id,
                f"âŒ ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰",
            )

    def _build_data_summary(self, summary: dict[str, Any], days: int) -> str:
        """æ„å»ºç”¨äº AI åˆ†æçš„ç»Ÿè®¡æ•°æ®æ‘˜è¦"""
        lines = []
        lines.append("ğŸ“Š Token ä½¿ç”¨ç»¼åˆåˆ†ææ•°æ®ï¼š")
        lines.append("")

        # æ•´ä½“æ¦‚å†µ
        lines.append("ã€æ•´ä½“æ¦‚å†µã€‘")
        lines.append(f"ç»Ÿè®¡å‘¨æœŸ: {days} å¤©")
        lines.append(f"æ€»è°ƒç”¨æ¬¡æ•°: {summary['total_calls']}")
        lines.append(f"æ€» Token æ¶ˆè€—: {summary['total_tokens']:,}")
        lines.append(f"å¹³å‡å“åº”æ—¶é—´: {summary['avg_duration']:.2f}s")
        lines.append(f"æ¶‰åŠæ¨¡å‹æ•°: {len(summary['models'])}")
        lines.append("")

        # æ—¶é—´ç»´åº¦
        daily_stats = summary.get("daily_stats", {})
        if daily_stats:
            dates = sorted(daily_stats.keys())
            total_daily_calls = sum(daily_stats[d]["calls"] for d in dates)
            total_daily_tokens = sum(daily_stats[d]["tokens"] for d in dates)
            avg_daily_calls = total_daily_calls / len(dates) if dates else 0
            avg_daily_tokens = total_daily_tokens / len(dates) if dates else 0

            # æ‰¾å‡ºé«˜å³°æ—¥
            peak_day = (
                max(dates, key=lambda d: daily_stats[d]["tokens"]) if dates else ""
            )
            peak_day_tokens = daily_stats[peak_day]["tokens"] if peak_day else 0

            lines.append("ã€æ—¶é—´ç»´åº¦ã€‘")
            lines.append(f"ç»Ÿè®¡å¤©æ•°: {len(dates)} å¤©")
            lines.append(f"æ¯æ—¥å¹³å‡è°ƒç”¨: {avg_daily_calls:.1f} æ¬¡")
            lines.append(f"æ¯æ—¥å¹³å‡ Token: {avg_daily_tokens:,.0f} ä¸ª")
            lines.append(f"é«˜å³°æ—¥æœŸ: {peak_day} ({peak_day_tokens:,} tokens)")
            lines.append("")

        # æ¨¡å‹ç»´åº¦
        models = summary.get("models", {})
        if models:
            lines.append("ã€æ¨¡å‹ç»´åº¦ã€‘")
            total_tokens_all = summary["total_tokens"]
            sorted_models = sorted(
                models.items(), key=lambda x: x[1]["tokens"], reverse=True
            )
            for model_name, model_data in sorted_models[:_STATS_MODEL_TOP_N]:
                calls = model_data["calls"]
                tokens = model_data["tokens"]
                prompt_tokens = model_data["prompt_tokens"]
                completion_tokens = model_data["completion_tokens"]
                token_pct = (
                    (tokens / total_tokens_all * 100) if total_tokens_all > 0 else 0
                )
                avg_per_call = tokens / calls if calls > 0 else 0
                io_ratio = completion_tokens / prompt_tokens if prompt_tokens > 0 else 0

                lines.append(f"æ¨¡å‹: {model_name}")
                lines.append(
                    f"  - è°ƒç”¨æ¬¡æ•°: {calls} ({calls / summary['total_calls'] * 100:.1f}%)"
                )
                lines.append(f"  - Token æ¶ˆè€—: {tokens:,} ({token_pct:.1f}%)")
                lines.append(f"  - å¹³å‡æ¯æ¬¡è°ƒç”¨: {avg_per_call:.0f} tokens")
                lines.append(
                    f"  - è¾“å…¥: {prompt_tokens:,} / è¾“å‡º: {completion_tokens:,}"
                )
                lines.append(f"  - è¾“å…¥/è¾“å‡ºæ¯”: 1:{io_ratio:.2f}")
                lines.append("")

            if len(sorted_models) > _STATS_MODEL_TOP_N:
                others = sorted_models[_STATS_MODEL_TOP_N:]
                others_calls = sum(int(item[1].get("calls", 0)) for item in others)
                others_tokens = sum(int(item[1].get("tokens", 0)) for item in others)
                others_pct = (
                    (others_tokens / total_tokens_all * 100)
                    if total_tokens_all > 0
                    else 0.0
                )
                lines.append(
                    f"å…¶ä½™ {len(others)} ä¸ªæ¨¡å‹åˆè®¡: è°ƒç”¨ {others_calls} æ¬¡, Token {others_tokens:,} ({others_pct:.1f}%)"
                )
                lines.append("")

        # è°ƒç”¨ç±»å‹ç»´åº¦
        call_types = summary.get("call_types", {})
        if call_types:
            lines.append("ã€è°ƒç”¨ç±»å‹ç»´åº¦ã€‘")
            sorted_types = sorted(
                call_types.items(), key=lambda item: int(item[1]), reverse=True
            )
            total_calls = max(1, int(summary.get("total_calls", 0)))
            for call_type, count in sorted_types[:_STATS_CALL_TYPE_TOP_N]:
                ratio = int(count) / total_calls * 100
                lines.append(f"- {call_type}: {count} æ¬¡ ({ratio:.1f}%)")
            if len(sorted_types) > _STATS_CALL_TYPE_TOP_N:
                rest_count = sum(
                    int(item[1]) for item in sorted_types[_STATS_CALL_TYPE_TOP_N:]
                )
                ratio = rest_count / total_calls * 100
                lines.append(
                    f"- å…¶ä»– {len(sorted_types) - _STATS_CALL_TYPE_TOP_N} ç±»: {rest_count} æ¬¡ ({ratio:.1f}%)"
                )
            lines.append("")

        # æ•ˆç‡æŒ‡æ ‡
        prompt_tokens = summary.get("prompt_tokens", 0)
        completion_tokens = summary.get("completion_tokens", 0)
        total_tokens = summary.get("total_tokens", 0)
        input_ratio = (prompt_tokens / total_tokens * 100) if total_tokens > 0 else 0
        output_ratio = (
            (completion_tokens / total_tokens * 100) if total_tokens > 0 else 0
        )
        output_per_input = completion_tokens / prompt_tokens if prompt_tokens > 0 else 0

        lines.append("ã€æ•ˆç‡æŒ‡æ ‡ã€‘")
        lines.append(f"è¾“å…¥ Token: {prompt_tokens:,} ({input_ratio:.1f}%)")
        lines.append(f"è¾“å‡º Token: {completion_tokens:,} ({output_ratio:.1f}%)")
        lines.append(f"è¾“å…¥/è¾“å‡ºæ¯”: 1:{output_per_input:.2f}")
        lines.append("")

        # è¶‹åŠ¿åˆ†æ
        if daily_stats and len(daily_stats) > 1:
            lines.append("ã€è¶‹åŠ¿åˆ†æã€‘")
            dates = sorted(daily_stats.keys())
            first_day_tokens = daily_stats[dates[0]]["tokens"]
            last_day_tokens = daily_stats[dates[-1]]["tokens"]
            trend_change = (
                ((last_day_tokens - first_day_tokens) / first_day_tokens * 100)
                if first_day_tokens > 0
                else 0
            )
            trend_desc = "å¢é•¿" if trend_change > 0 else "ä¸‹é™"
            lines.append(
                f"æ€»ä½“è¶‹åŠ¿: {trend_desc} {abs(trend_change):.1f}% (ä»é¦–æ—¥åˆ°æœ«æ—¥)"
            )
            lines.append("")

        summary_text = "\n".join(lines)
        if len(summary_text) > _STATS_DATA_SUMMARY_MAX_CHARS:
            trimmed = summary_text[: _STATS_DATA_SUMMARY_MAX_CHARS - 80].rstrip()
            summary_text = (
                f"{trimmed}\n\n[æ•°æ®æ‘˜è¦å·²æˆªæ–­ï¼Œæ€»é•¿åº¦ {len(summary_text)} å­—ç¬¦ï¼Œ"
                f"ä»…ä¿ç•™å‰ {_STATS_DATA_SUMMARY_MAX_CHARS} å­—ç¬¦]"
            )
            logger.info(
                "[Stats] æ•°æ®æ‘˜è¦è¿‡é•¿å·²æˆªæ–­: original_len=%s max_len=%s",
                len("\n".join(lines)),
                _STATS_DATA_SUMMARY_MAX_CHARS,
            )
        return summary_text

    def set_stats_analysis_result(
        self, group_id: int, request_id: str, analysis: str
    ) -> None:
        """è®¾ç½® AI åˆ†æç»“æœï¼ˆç”±é˜Ÿåˆ—å¤„ç†å™¨è°ƒç”¨ï¼‰"""
        event = self._stats_analysis_events.get(request_id)
        if not event:
            logger.warning(
                "[StatsAnalysis] æœªæ‰¾åˆ°ç­‰å¾…äº‹ä»¶ï¼Œç¾¤: %s, è¯·æ±‚: %s",
                group_id,
                request_id,
            )
            return
        self._stats_analysis_results[request_id] = analysis
        event.set()

    async def _handle_stats_help(self, group_id: int) -> None:
        """å‘é€ stats å‘½ä»¤çš„å¸®åŠ©ä¿¡æ¯"""
        help_text = """ğŸ“Š /stats å‘½ä»¤å¸®åŠ©

ç”¨æ³•ï¼š
  /stats [æ—¶é—´èŒƒå›´]

æ—¶é—´èŒƒå›´æ ¼å¼ï¼š
  7d  - æœ€è¿‘ 7 å¤©ï¼ˆé»˜è®¤ï¼‰
  1w  - æœ€è¿‘ 1 å‘¨
  30d - æœ€è¿‘ 30 å¤©
  1m  - æœ€è¿‘ 1 ä¸ªæœˆ

ç¤ºä¾‹ï¼š
  /stats        - æ˜¾ç¤ºæœ€è¿‘ 7 å¤©çš„ç»Ÿè®¡
  /stats 30d    - æ˜¾ç¤ºæœ€è¿‘ 30 å¤©çš„ç»Ÿè®¡
  /stats --help - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        await self.sender.send_group_message(group_id, help_text)

    def _build_stats_forward_nodes(
        self,
        summary: dict[str, Any],
        img_dir: Path,
        days: int,
        ai_analysis: str = "",
    ) -> list[dict[str, Any]]:
        """æ„å»ºç”¨äºåˆå¹¶è½¬å‘çš„ç»Ÿè®¡å›¾è¡¨èŠ‚ç‚¹åˆ—è¡¨"""
        nodes = []
        bot_qq = str(self.config.bot_qq)

        # è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæ¶ˆæ¯èŠ‚ç‚¹
        def add_node(content: str) -> None:
            nodes.append(
                {
                    "type": "node",
                    "data": {"name": "Bot", "uin": bot_qq, "content": content},
                }
            )

        add_node(f"ğŸ“Š æœ€è¿‘ {days} å¤©çš„ Token ä½¿ç”¨ç»Ÿè®¡ï¼š")

        # æ·»åŠ æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡
        for img_name in ["line_chart", "bar_chart", "pie_chart", "table"]:
            img_path = img_dir / f"stats_{img_name}.png"
            if img_path.exists():
                add_node(f"[CQ:image,file={str(img_path.absolute())}]")

        # æ·»åŠ æ–‡æœ¬æ‘˜è¦
        summary_text = f"""ğŸ“ˆ æ‘˜è¦æ±‡æ€»:
â€¢ æ€»è°ƒç”¨æ¬¡æ•°: {summary["total_calls"]}
â€¢ æ€»æ¶ˆè€— Tokens: {summary["total_tokens"]:,}
  â””â”€ è¾“å…¥: {summary["prompt_tokens"]:,}
  â””â”€ è¾“å‡º: {summary["completion_tokens"]:,}
â€¢ å¹³å‡è€—æ—¶: {summary["avg_duration"]:.2f}s
â€¢ æ¶‰åŠæ¨¡å‹æ•°: {len(summary["models"])}"""
        add_node(summary_text)

        # æ·»åŠ  AI åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if ai_analysis:
            add_node(f"ğŸ¤– AI æ™ºèƒ½åˆ†æ\n{ai_analysis}")

        return nodes

    async def _generate_line_chart(
        self, summary: dict[str, Any], img_dir: Path, days: int
    ) -> None:
        """ç”ŸæˆæŠ˜çº¿å›¾ï¼šæ—¶é—´è¶‹åŠ¿"""
        daily_stats = summary["daily_stats"]
        if not daily_stats:
            return

        # å‡†å¤‡æ•°æ®
        dates = sorted(daily_stats.keys())
        tokens = [daily_stats[d]["tokens"] for d in dates]
        prompt_tokens = [daily_stats[d]["prompt_tokens"] for d in dates]
        completion_tokens = [daily_stats[d]["completion_tokens"] for d in dates]

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 7))

        # ç»˜åˆ¶æŠ˜çº¿
        ax.plot(
            dates, tokens, marker="o", linewidth=2, label="Total Token", color="#2196F3"
        )
        ax.plot(
            dates,
            prompt_tokens,
            marker="s",
            linewidth=2,
            label="Input Token",
            color="#4CAF50",
        )
        ax.plot(
            dates,
            completion_tokens,
            marker="^",
            linewidth=2,
            label="Output Token",
            color="#FF9800",
        )

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(
            f"Token Usage Trend for Last {days} Days", fontsize=16, fontweight="bold"
        )
        ax.set_xlabel("Date", fontsize=12)
        ax.set_ylabel("Token Count", fontsize=12)
        ax.legend(loc="upper left", fontsize=10)
        ax.grid(True, alpha=0.3)

        # æ—‹è½¬ x è½´æ ‡ç­¾
        plt.xticks(rotation=45, ha="right")

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_line_chart.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def _generate_bar_chart(self, summary: dict[str, Any], img_dir: Path) -> None:
        """ç”ŸæˆæŸ±çŠ¶å›¾ï¼šæ¨¡å‹å¯¹æ¯”"""
        models = summary["models"]
        if not models:
            return

        # å‡†å¤‡æ•°æ®
        model_names = list(models.keys())
        tokens = [models[m]["tokens"] for m in model_names]
        prompt_tokens = [models[m]["prompt_tokens"] for m in model_names]
        completion_tokens = [models[m]["completion_tokens"] for m in model_names]

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 8))

        # è®¾ç½®æŸ±çŠ¶å›¾ä½ç½®
        x = range(len(model_names))
        width = 0.25

        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars1 = ax.bar(
            [i - width for i in x],
            tokens,
            width,
            label="Total Token",
            color="#2196F3",
            alpha=0.8,
        )
        bars2 = ax.bar(
            x,
            prompt_tokens,
            width,
            label="Input Token",
            color="#4CAF50",
            alpha=0.8,
        )
        bars3 = ax.bar(
            [i + width for i in x],
            completion_tokens,
            width,
            label="Output Token",
            color="#FF9800",
            alpha=0.8,
        )

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title("Token Usage Comparison by Model", fontsize=16, fontweight="bold")
        ax.set_xlabel("Model", fontsize=12)
        ax.set_ylabel("Token Count", fontsize=12)
        ax.set_xticks(x)
        ax.set_xticklabels(model_names, rotation=45, ha="right")
        ax.legend(loc="upper right", fontsize=10)
        ax.grid(True, alpha=0.3, axis="y")

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2, bars3]:
            for bar in bars:
                height = bar.get_height()
                if height > 0:
                    ax.text(
                        bar.get_x() + bar.get_width() / 2.0,
                        height,
                        f"{int(height):,}",
                        ha="center",
                        va="bottom",
                        fontsize=8,
                    )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_bar_chart.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def _generate_pie_chart(self, summary: dict[str, Any], img_dir: Path) -> None:
        """ç”Ÿæˆé¥¼å›¾ï¼šè¾“å…¥/è¾“å‡ºæ¯”ä¾‹"""
        prompt_tokens = summary["prompt_tokens"]
        completion_tokens = summary["completion_tokens"]

        if prompt_tokens == 0 and completion_tokens == 0:
            return

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 8))

        # å‡†å¤‡æ•°æ®
        labels = ["Input Token", "Output Token"]
        sizes = [prompt_tokens, completion_tokens]
        colors = ["#4CAF50", "#FF9800"]
        explode = (0.05, 0.05)  # çªå‡ºæ˜¾ç¤º

        # ç»˜åˆ¶é¥¼å›¾
        wedges, *_ = ax.pie(
            sizes,
            explode=explode,
            labels=labels,
            colors=colors,
            autopct="%1.1f%%",
            startangle=90,
            textprops={"fontsize": 12},
        )

        # è®¾ç½®æ ‡é¢˜
        ax.set_title("Input/Output Token Ratio", fontsize=16, fontweight="bold", pad=20)

        # æ·»åŠ å›¾ä¾‹
        ax.legend(
            wedges,
            [f"{labels[i]}: {sizes[i]:,}" for i in range(len(labels))],
            loc="center left",
            bbox_to_anchor=(1, 0, 0.5, 1),
            fontsize=10,
        )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_pie_chart.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def _generate_stats_table(
        self, summary: dict[str, Any], img_dir: Path
    ) -> None:
        """ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼"""
        models = summary["models"]
        if not models:
            return

        # å‡†å¤‡æ•°æ®
        model_names = list(models.keys())
        data = []
        for model in model_names:
            m = models[model]
            data.append(
                [
                    model,
                    m["calls"],
                    f"{m['tokens']:,}",
                    f"{m['prompt_tokens']:,}",
                    f"{m['completion_tokens']:,}",
                ]
            )

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 9))
        ax.axis("tight")
        ax.axis("off")

        # åˆ›å»ºè¡¨æ ¼
        table = ax.table(
            cellText=data,
            colLabels=["Model", "Calls", "Total Token", "Input Token", "Output Token"],
            cellLoc="center",
            loc="center",
        )

        # è®¾ç½®è¡¨æ ¼æ ·å¼
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)

        # è®¾ç½®è¡¨å¤´æ ·å¼
        for i in range(5):
            table[(0, i)].set_facecolor("#2196F3")
            table[(0, i)].set_text_props(weight="bold", color="white")

        # è®¾ç½®è¡Œæ ·å¼
        for i in range(1, len(data) + 1):
            for j in range(5):
                if i % 2 == 0:
                    table[(i, j)].set_facecolor("#f0f0f0")

        # è®¾ç½®æ ‡é¢˜
        ax.set_title(
            "Model Usage Statistics Details", fontsize=16, fontweight="bold", pad=20
        )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_table.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def dispatch(
        self, group_id: int, sender_id: int, command: dict[str, Any]
    ) -> None:
        """åˆ†å‘å¹¶æ‰§è¡Œå…·ä½“çš„å‘½ä»¤

        å‚æ•°:
            group_id: æ¶ˆæ¯æ¥æºç¾¤ç»„
            sender_id: å‘é€è€… QQ å·
            command: è§£æå‡ºçš„å‘½ä»¤æ•°æ®ç»“æ„
        """
        start_time = time.perf_counter()
        cmd_name = str(command["name"])
        cmd_args = command["args"]

        logger.info("[å‘½ä»¤] æ‰§è¡Œå‘½ä»¤: /%s | å‚æ•°=%s", cmd_name, cmd_args)
        logger.debug(
            "[å‘½ä»¤] åˆ†å‘è¯·æ±‚: group=%s sender=%s cmd=%s args_count=%s",
            group_id,
            sender_id,
            cmd_name,
            len(cmd_args),
        )

        meta = self.command_registry.resolve(cmd_name)
        if meta is None:
            logger.info("[å‘½ä»¤] æœªçŸ¥å‘½ä»¤: /%s", cmd_name)
            await self.sender.send_group_message(
                group_id,
                f"âŒ æœªçŸ¥å‘½ä»¤: {cmd_name}\nä½¿ç”¨ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤",
            )
            return

        logger.info(
            "[å‘½ä»¤] å‘½ä»¤åŒ¹é…æˆåŠŸ: input=/%s resolved=/%s permission=%s rate_limit=%s",
            cmd_name,
            meta.name,
            meta.permission,
            meta.rate_limit,
        )

        allowed, role_name = self._check_command_permission(meta, sender_id)
        if not allowed:
            logger.warning(
                "[å‘½ä»¤] æƒé™æ ¡éªŒå¤±è´¥: cmd=/%s sender=%s required=%s",
                meta.name,
                sender_id,
                role_name,
            )
            await self._send_no_permission(group_id, sender_id, meta.name, role_name)
            return

        logger.debug(
            "[å‘½ä»¤] æƒé™æ ¡éªŒé€šè¿‡: cmd=/%s sender=%s",
            meta.name,
            sender_id,
        )

        if not await self._check_command_rate_limit(meta, group_id, sender_id):
            logger.warning(
                "[å‘½ä»¤] é€Ÿç‡é™åˆ¶æ‹¦æˆª: cmd=/%s group=%s sender=%s",
                meta.name,
                group_id,
                sender_id,
            )
            return

        logger.debug(
            "[å‘½ä»¤] é€Ÿç‡é™åˆ¶é€šè¿‡: cmd=/%s group=%s sender=%s",
            meta.name,
            group_id,
            sender_id,
        )

        context = CommandContext(
            group_id=group_id,
            sender_id=sender_id,
            config=self.config,
            sender=self.sender,
            ai=self.ai,
            faq_storage=self.faq_storage,
            onebot=self.onebot,
            security=self.security,
            queue_manager=self.queue_manager,
            rate_limiter=self.rate_limiter,
            dispatcher=self,
            registry=self.command_registry,
        )

        try:
            await self.command_registry.execute(meta, cmd_args, context)
            duration = time.perf_counter() - start_time
            logger.info(
                "[å‘½ä»¤] åˆ†å‘å®Œæˆ: cmd=/%s duration=%.3fs",
                meta.name,
                duration,
            )
        except Exception as e:
            duration = time.perf_counter() - start_time
            error_id = uuid4().hex[:8]
            logger.exception(
                "[å‘½ä»¤] æ‰§è¡Œå¤±è´¥: cmd=/%s error_id=%s err=%s",
                meta.name,
                error_id,
                e,
            )
            logger.error(
                "[å‘½ä»¤] åˆ†å‘å¤±è´¥: cmd=/%s duration=%.3fs error_id=%s",
                meta.name,
                duration,
                error_id,
            )
            await self.sender.send_group_message(
                group_id,
                f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰",
            )

    def _check_command_permission(
        self,
        command_meta: CommandMeta,
        sender_id: int,
    ) -> tuple[bool, str]:
        permission = command_meta.permission
        if permission == "superadmin":
            return self.config.is_superadmin(sender_id), "è¶…çº§ç®¡ç†å‘˜"
        if permission == "admin":
            return self.config.is_admin(sender_id), "ç®¡ç†å‘˜"
        return True, ""

    async def _check_command_rate_limit(
        self,
        command_meta: CommandMeta,
        group_id: int,
        sender_id: int,
    ) -> bool:
        rate_limit = command_meta.rate_limit
        if rate_limit == "none":
            logger.debug(
                "[å‘½ä»¤] å‘½ä»¤æ— éœ€é™æµ: cmd=/%s",
                command_meta.name,
            )
            return True

        if rate_limit == "stats":
            if self.rate_limiter is None:
                logger.warning(
                    "[å‘½ä»¤] stats é™æµå™¨ç¼ºå¤±ï¼Œè·³è¿‡é™æµ: cmd=/%s",
                    command_meta.name,
                )
                return True
            allowed, remaining = self.rate_limiter.check_stats(sender_id)
            if not allowed:
                minutes = remaining // 60
                seconds = remaining % 60
                time_str = f"{minutes}åˆ†{seconds}ç§’" if minutes > 0 else f"{seconds}ç§’"
                await self.sender.send_group_message(
                    group_id,
                    f"â³ /stats å‘½ä»¤å¤ªé¢‘ç¹ï¼Œè¯· {time_str}åå†è¯•",
                )
                return False
            self.rate_limiter.record_stats(sender_id)
            logger.debug(
                "[å‘½ä»¤] stats é™æµè®°å½•æˆåŠŸ: cmd=/%s sender=%s",
                command_meta.name,
                sender_id,
            )
            return True

        allowed, remaining = self.security.check_rate_limit(sender_id)
        if not allowed:
            await self.sender.send_group_message(
                group_id,
                f"â³ æ“ä½œå¤ªé¢‘ç¹ï¼Œè¯· {remaining} ç§’åå†è¯•",
            )
            return False
        self.security.record_rate_limit(sender_id)
        logger.debug(
            "[å‘½ä»¤] é»˜è®¤é™æµè®°å½•æˆåŠŸ: cmd=/%s sender=%s",
            command_meta.name,
            sender_id,
        )
        return True

    async def _send_no_permission(
        self, group_id: int, sender_id: int, cmd_name: str, required_role: str
    ) -> None:
        logger.warning("[å‘½ä»¤] æƒé™ä¸è¶³: sender=%s cmd=/%s", sender_id, cmd_name)
        await self.sender.send_group_message(
            group_id, f"âš ï¸ æƒé™ä¸è¶³ï¼šåªæœ‰{required_role}å¯ä»¥ä½¿ç”¨æ­¤å‘½ä»¤"
        )

    async def _handle_bugfix(
        self, group_id: int, admin_id: int, args: list[str]
    ) -> None:
        """å¤„ç† /bugfix å‘½ä»¤ï¼Œé€šè¿‡åˆ†æèŠå¤©è®°å½•è‡ªåŠ¨ç”Ÿæˆ FAQ å½’æ¡£"""
        # 1. å‚æ•°è§£æ
        parsed = self._parse_bugfix_args(args)
        if isinstance(parsed, str):
            await self.sender.send_group_message(group_id, parsed)
            return

        target_qqs, start_date, end_date, start_str, end_str = parsed

        await self.sender.send_group_message(
            group_id, "ğŸ” æ­£åœ¨è·å–å¯¹è¯è®°å½•è¿›è¡Œå›æº¯åˆ†æ..."
        )

        try:
            # 2. è·å–å¹¶å¤„ç†æ¶ˆæ¯
            messages = await self._fetch_messages(
                group_id, target_qqs, start_date, end_date
            )
            if not messages:
                await self.sender.send_group_message(
                    group_id, "âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¯¹è¯è®°å½•ã€‚"
                )
                return

            processed_text = await self._process_messages(messages)

            # 3. ç”Ÿæˆæ‘˜è¦æ€»ç»“
            summary = await self._obtain_bugfix_summary(group_id, processed_text)

            # 4. ç”Ÿæˆæ ‡é¢˜å¹¶å…¥åº“
            title = extract_faq_title(summary)
            if not title or title == "æœªå‘½åé—®é¢˜":
                title = await self.ai.generate_title(summary)

            faq = await self.faq_storage.create(
                group_id=group_id,
                target_qq=target_qqs[0],
                start_time=start_str,
                end_time=end_str,
                title=title,
                content=summary,
            )

            result_msg = f"âœ… Bug ä¿®å¤åˆ†æå®Œæˆï¼\n\nğŸ“Œ FAQ ID: {faq.id}\nğŸ“‹ æ ‡é¢˜: {title}\n\n{summary}"
            await self.sender.send_group_message(group_id, result_msg)

        except Exception as e:
            error_id = uuid4().hex[:8]
            logger.exception("Bugfix å¤±è´¥: error_id=%s err=%s", error_id, e)
            await self.sender.send_group_message(
                group_id,
                f"âŒ Bug ä¿®å¤åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰",
            )

    def _parse_bugfix_args(
        self, args: list[str]
    ) -> tuple[list[int], datetime, datetime, str, str] | str:
        """è§£æ bugfix å‘½ä»¤çš„å‚æ•°"""
        if len(args) < 3:
            return (
                "âŒ ç”¨æ³•: /bugfix <QQå·1> [QQå·2] ... <å¼€å§‹æ—¶é—´> <ç»“æŸæ—¶é—´>\n"
                "æ—¶é—´æ ¼å¼: YYYY/MM/DD/HH:MMï¼Œç»“æŸæ—¶é—´å¯ç”¨ now\n"
                "ç¤ºä¾‹: /bugfix 123456 2024/12/01/09:00 now"
            )

        try:
            target_qqs = [int(arg) for arg in args[:-2]]
            start_str, end_str_raw = args[-2], args[-1]
            start_date = datetime.strptime(start_str, "%Y/%m/%d/%H:%M")

            if end_str_raw.lower() == "now":
                end_date, end_str = datetime.now(), "now"
            else:
                end_date, end_str = (
                    datetime.strptime(end_str_raw, "%Y/%m/%d/%H:%M"),
                    end_str_raw,
                )

            return target_qqs, start_date, end_date, start_str, end_str
        except ValueError:
            return "âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼šQQå·åº”ä¸ºæ•°å­—ï¼Œæ—¶é—´æ ¼å¼åº”ä¸º YYYY/MM/DD/HH:MMã€‚"

    async def _obtain_bugfix_summary(self, group_id: int, processed_text: str) -> str:
        """åˆ©ç”¨ AI ç”ŸæˆèŠå¤©è®°å½•çš„ Bug åˆ†ææ‘˜è¦"""
        total_tokens = self.ai.count_tokens(processed_text)
        max_tokens = self.config.chat_model.max_tokens

        if total_tokens <= max_tokens:
            return str(await self.ai.summarize_chat(processed_text))

        await self.sender.send_group_message(
            group_id, f"ğŸ“Š æ¶ˆæ¯è¾ƒé•¿ï¼ˆ{total_tokens} tokensï¼‰ï¼Œæ­£åœ¨åˆ†æ®µå¤„ç†..."
        )
        chunks = self.ai.split_messages_by_tokens(processed_text, max_tokens)
        summaries = [await self.ai.summarize_chat(chunk) for chunk in chunks]
        return str(await self.ai.merge_summaries(summaries))

    async def _fetch_messages(
        self,
        group_id: int,
        target_qqs: list[int],
        start_date: datetime,
        end_date: datetime,
    ) -> list[dict[str, Any]]:
        batch = await self.onebot.get_group_msg_history(group_id, count=2500)
        if not batch:
            return []
        target_qqs_set = set(target_qqs)
        results = []
        for msg in batch:
            msg_time = parse_message_time(msg)
            if (
                start_date <= msg_time <= end_date
                and get_message_sender_id(msg) in target_qqs_set
            ):
                results.append(msg)
        return sorted(results, key=lambda m: m.get("time", 0))

    async def _process_messages(self, messages: list[dict[str, Any]]) -> str:
        lines = []
        for msg in messages:
            sender_id = get_message_sender_id(msg)
            msg_time = parse_message_time(msg).strftime("%Y-%m-%d %H:%M:%S")
            content = get_message_content(msg)
            text_parts = []
            for segment in content:
                seg_type, seg_data = segment.get("type", ""), segment.get("data", {})
                if seg_type == "text":
                    text_parts.append(seg_data.get("text", ""))
                elif seg_type == "image":
                    file = seg_data.get("file", "") or seg_data.get("url", "")
                    if file:
                        try:
                            url = await self.onebot.get_image(file)
                            if url:
                                res = await self.ai.analyze_multimodal(url, "image")
                                text_parts.append(
                                    f"[pic]<desc>{res.get('description', '')}</desc><text>{res.get('ocr_text', '')}</text>[/pic]"
                                )
                        except Exception:
                            text_parts.append("[pic]<desc>å›¾ç‰‡å¤„ç†å¤±è´¥</desc>[/pic]")
                elif seg_type == "at":
                    text_parts.append(f"@{seg_data.get('qq', '')}")
            if text_parts:
                lines.append(f"[{msg_time}] {sender_id}: {''.join(text_parts)}")
        return "\n".join(lines)
