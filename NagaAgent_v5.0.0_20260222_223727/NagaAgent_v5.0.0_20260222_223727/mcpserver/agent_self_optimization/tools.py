#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªæˆ‘ä¼˜åŒ–å·¥å…·ç±»
æä¾›è‡ªæˆ‘ä¼˜åŒ–ç›¸å…³çš„å·¥å…·å®ç°
"""

import asyncio
import logging
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
import ast

logger = logging.getLogger(__name__)


class SelfOptimizationTools:
    """è‡ªæˆ‘ä¼˜åŒ–å·¥å…·ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–"""
        self.optimizer = None
        self._init_optimizer()

    def _init_optimizer(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        try:
            from pathlib import Path
            from system.self_optimization import init_global_optimizer
            from system.config import config

            project_root = Path.cwd()
            self.optimizer = init_global_optimizer(str(project_root), config)
            logger.info("[SelfOptimizationTools] ä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"[SelfOptimizationTools] ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

    async def check_system_health(self, args: Dict[str, Any]) -> str:
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            health_report = await self.optimizer.health_monitor.check_health()
            health_summary = self.optimizer.health_monitor.get_health_summary()

            result = f"""ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥æŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æ€»ä½“çŠ¶æ€: {health_summary.get('status', 'unknown').upper()}
â° æ£€æŸ¥æ—¶é—´: {health_summary.get('timestamp', '')}

ğŸ“± ç³»ç»Ÿèµ„æº:
  â€¢ CPUä½¿ç”¨ç‡: {health_summary['details']['system'].get('cpu_usage', 0)}%
  â€¢ å†…å­˜ä½¿ç”¨ç‡: {health_summary['details']['system'].get('memory_usage', 0)}%
  â€¢ ç£ç›˜ä½¿ç”¨ç‡: {health_summary['details']['system'].get('disk_usage', 0)}%

ğŸ”Œ æœåŠ¡çŠ¶æ€:"""

            for service_name, status in health_summary['details']['services'].items():
                status_icon = "âœ…" if status.get('status') == 'healthy' else "âŒ"
                result += f"\n  {status_icon} {service_name}: {status.get('status', 'unknown')}"

            # æ·»åŠ å‘Šè­¦ä¿¡æ¯
            active_alerts = health_summary.get('active_alerts', 0)
            if active_alerts > 0:
                result += f"\n\nâš ï¸  æ£€æµ‹åˆ° {active_alerts} ä¸ªæ´»åŠ¨å‘Šè­¦"

            # æ·»åŠ ä¼˜åŒ–å»ºè®®
            suggestions = self.optimizer.health_monitor.get_optimization_suggestions()
            if suggestions:
                result += "\n\nğŸ’¡ ä¼˜åŒ–å»ºè®®:"
                for i, suggestion in enumerate(suggestions[:3], 1):
                    result += f"\n  {i}. [{suggestion.get('severity', 'info')}] {suggestion.get('title', '')}"
                    result += f"\n     {suggestion.get('suggestion', '')}"

            return result.strip()

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] å¥åº·æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)
            return f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"

    async def analyze_performance(self, args: Dict[str, Any]) -> str:
        """åˆ†æç³»ç»Ÿæ€§èƒ½"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            operation_name = args.get("operation_name")

            if operation_name:
                report = self.optimizer.performance_profiler.get_report(operation_name)
                return f"""ğŸ“ˆ æ€§èƒ½åˆ†ææŠ¥å‘Š: {operation_name}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ è°ƒç”¨æ¬¡æ•°: {report.get('count', 0)}
â€¢ å¹³å‡è€—æ—¶: {report.get('avg_time', 0)} ç§’
â€¢ æœ€å°è€—æ—¶: {report.get('min_time', 0)} ç§’
â€¢ æœ€å¤§è€—æ—¶: {report.get('max_time', 0)} ç§’
â€¢ é”™è¯¯ç‡: {report.get('error_rate', 0)}%
â€¢ é”™è¯¯æ¬¡æ•°: {report.get('errors', 0)}"""
            else:
                report = self.optimizer.performance_profiler.get_report()

                result = f"""ğŸ“ˆ æ€§èƒ½åˆ†ææŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æ€»è§ˆ:
  â€¢ æ€»æ“ä½œæ•°: {report['summary'].get('total_operations', 0)}
  â€¢ æ€»è°ƒç”¨æ¬¡æ•°: {report['summary'].get('total_calls', 0)}
  â€¢ æ€»é”™è¯¯æ¬¡æ•°: {report['summary'].get('total_errors', 0)}
  â€¢ ç”Ÿæˆæ—¶é—´: {report['summary'].get('generated_at', '')}

ğŸŒ æœ€æ…¢æ“ä½œï¼ˆå‰5ï¼‰:"""

                top_slowest = report.get('top_slowest', [])
                for i, (name, stats) in enumerate(top_slowest[:5], 1):
                    result += f"\n  {i}. {name}: å¹³å‡ {stats.get('avg_time', 0)} ç§’ ({stats.get('count', 0)} æ¬¡è°ƒç”¨)"

                result += "\n\nğŸ”„ æœ€é¢‘ç¹æ“ä½œï¼ˆå‰5ï¼‰:"
                top_frequent = report.get('top_frequent', [])
                for i, (name, stats) in enumerate(top_frequent[:5], 1):
                    result += f"\n  {i}. {name}: {stats.get('count', 0)} æ¬¡è°ƒç”¨"

                # è¯†åˆ«ç“¶é¢ˆ
                bottlenecks = self.optimizer.performance_profiler.identify_bottlenecks()
                if bottlenecks:
                    result += "\n\nâš ï¸  æ€§èƒ½ç“¶é¢ˆ:"
                    for bottleneck in bottlenecks[:3]:
                        result += f"\n  â€¢ {bottleneck.get('operation', 'unknown')}: {bottleneck.get('suggestion', '')}"

                return result.strip()

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] æ€§èƒ½åˆ†æå¤±è´¥: {e}", exc_info=True)
            return f"æ€§èƒ½åˆ†æå¤±è´¥: {str(e)}"

    async def run_optimization(self, args: Dict[str, Any]) -> str:
        """è¿è¡Œè‡ªåŠ¨ä¼˜åŒ–"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            report = await self.optimizer.run_manual_optimization()

            summary = report.get('summary', {})
            status = summary.get('status', 'unknown')

            result = f"""ğŸ”§ è‡ªåŠ¨ä¼˜åŒ–æŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š çŠ¶æ€: {status.upper()}
â° æ£€æŸ¥æ—¶é—´: {report.get('timestamp', '')}
â±ï¸  è€—æ—¶: {summary.get('elapsed_seconds', 0)} ç§’

ğŸ¥ å¥åº·çŠ¶æ€: {summary.get('health_status', 'unknown')}"""

            # ä¼˜åŒ–ç»“æœ
            optimizations = report.get('optimizations_applied', [])
            if optimizations:
                result += f"\n\nâœ… å·²åº”ç”¨ä¼˜åŒ– ({len(optimizations)} é¡¹):"
                for i, opt in enumerate(optimizations, 1):
                    result += f"\n  {i}. [{opt.get('status', 'unknown')}] {opt.get('type', 'unknown')}"
                    if opt.get('message'):
                        result += f"\n     {opt.get('message', '')}"
            else:
                result += "\n\nâœ“ æœªåº”ç”¨ä¼˜åŒ–ï¼ˆç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼‰"

            # ä¼˜åŒ–å»ºè®®
            recommendations = report.get('recommendations', [])
            if recommendations:
                result += f"\n\nğŸ’¡ ä¼˜åŒ–å»ºè®® ({len(recommendations)} é¡¹):"
                for i, rec in enumerate(recommendations[:5], 1):
                    severity = rec.get('severity', 'info')
                    result += f"\n  {i}. [{severity.upper()}] {rec.get('title', '')}"
                    if rec.get('suggestion'):
                        result += f"\n     {rec.get('suggestion', '')}"

            return result.strip()

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] ä¼˜åŒ–æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return f"ä¼˜åŒ–æ‰§è¡Œå¤±è´¥: {str(e)}"

    async def analyze_code_quality(self, args: Dict[str, Any]) -> str:
        """åˆ†æä»£ç è´¨é‡"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            result = await self.optimizer.run_code_analysis()

            code_quality = result.get('code_quality', {})
            refactoring_suggestions = result.get('refactoring_suggestions', [])

            output = f"""ğŸ“ ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ä»£ç ç»Ÿè®¡:
  â€¢ æ€»æ–‡ä»¶æ•°: {code_quality.get('complexity', {}).get('total_files', 0)}
  â€¢ æ€»å‡½æ•°æ•°: {code_quality.get('complexity', {}).get('total_functions', 0)}
  â€¢ æ€»ç±»æ•°: {code_quality.get('complexity', {}).get('total_classes', 0)}
  â€¢ æ€»ä»£ç è¡Œæ•°: {code_quality.get('complexity', {}).get('total_lines', 0)}

âš ï¸  é«˜å¤æ‚åº¦å‡½æ•°: {code_quality.get('complexity', {}).get('high_complexity_count', 0)} ä¸ª
ğŸ”„ é‡å¤ä»£ç : {code_quality.get('duplication', {}).get('duplicated_signatures', 0)} å¤„"""

            # é‡æ„å»ºè®®
            if refactoring_suggestions:
                output += f"\n\nğŸ”§ é‡æ„å»ºè®® ({len(refactoring_suggestions)} é¡¹):"
                for i, suggestion in enumerate(refactoring_suggestions[:5], 1):
                    severity = suggestion.get('severity', 'info')
                    output += f"\n  {i}. [{severity.upper()}] {suggestion.get('title', '')}"
                    output += f"\n     æ–‡ä»¶: {suggestion.get('file', '')}"
                    if suggestion.get('suggestion'):
                        output += f"\n     {suggestion.get('suggestion', '')}"

            # AIå»ºè®®
            ai_suggestions = result.get('ai_suggestions', [])
            if ai_suggestions:
                output += f"\n\nğŸ¤– AIä¼˜åŒ–å»ºè®® ({len(ai_suggestions)} é¡¹):"
                for i, suggestion in enumerate(ai_suggestions, 1):
                    output += f"\n  {i}. [{suggestion.get('priority', 'medium').upper()}] {suggestion.get('title', '')}"
                    output += f"\n     {suggestion.get('description', '')}"
                    output += f"\n     è¡ŒåŠ¨: {suggestion.get('action', '')}"

            return output.strip()

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] ä»£ç è´¨é‡åˆ†æå¤±è´¥: {e}", exc_info=True)
            return f"ä»£ç è´¨é‡åˆ†æå¤±è´¥: {str(e)}"

    async def export_reports(self, args: Dict[str, Any]) -> str:
        """å¯¼å‡ºæ‰€æœ‰æŠ¥å‘Š"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            output_path = self.optimizer.export_full_report()

            return f"""ğŸ“„ æŠ¥å‘Šå¯¼å‡ºæˆåŠŸ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… å®Œæ•´æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}

æŠ¥å‘ŠåŒ…å«:
â€¢ å¥åº·æ£€æŸ¥æŠ¥å‘Š
â€¢ æ€§èƒ½åˆ†ææŠ¥å‘Š
â€¢ ä¼˜åŒ–æ‰§è¡ŒæŠ¥å‘Š
â€¢ ä»£ç è´¨é‡æŠ¥å‘Š
â€¢ ä¼˜åŒ–å»ºè®®æ±‡æ€»"""

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {e}", exc_info=True)
            return f"æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {str(e)}"

    async def get_status(self, args: Dict[str, Any]) -> str:
        """è·å–è‡ªæˆ‘ä¼˜åŒ–ç³»ç»ŸçŠ¶æ€"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            status = self.optimizer.get_status()

            result = f"""ğŸ” è‡ªæˆ‘ä¼˜åŒ–ç³»ç»ŸçŠ¶æ€
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸƒ è¿è¡ŒçŠ¶æ€: {'âœ… è¿è¡Œä¸­' if status.get('running') else 'â¹ï¸  å·²åœæ­¢'}
â° æ£€æŸ¥é—´éš”: {status.get('check_interval', 0)} ç§’
ğŸ“Š æ€»è¿è¡Œæ¬¡æ•°: {status.get('total_runs', 0)}

ğŸ¥ å¥åº·çŠ¶æ€: {status.get('health_status', 'unknown').upper()}"""

            # æœ€åä¸€æ¬¡è¿è¡Œ
            last_run = status.get('last_run')
            if last_run:
                summary = last_run.get('summary', {})
                result += f"""

ğŸ“‹ æœ€åä¸€æ¬¡è¿è¡Œ:
  â€¢ æ—¶é—´: {last_run.get('timestamp', '')}
  â€¢ çŠ¶æ€: {summary.get('status', 'unknown').upper()}
  â€¢ è€—æ—¶: {summary.get('elapsed_seconds', 0)} ç§’
  â€¢ åº”ç”¨ä¼˜åŒ–: {summary.get('optimizations_count', 0)} é¡¹
  â€¢ ç”Ÿæˆå»ºè®®: {summary.get('recommendations_count', 0)} é¡¹"""

            return result.strip()

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] è·å–çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}"

    async def fix_code_issues(self, args: Dict[str, Any]) -> str:
        """ä¿®å¤æ£€æµ‹åˆ°çš„ä»£ç é—®é¢˜ï¼ˆå¸¦å¤‡ä»½å’Œè‡ªåŠ¨å›æ»šåŠŸèƒ½ï¼‰"""
        try:
            if not self.optimizer:
                return "è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿæœªåˆå§‹åŒ–"

            auto_fix = args.get("auto_fix", False)
            issue_types = args.get("issue_types", [])

            # è·å–ä»£ç è´¨é‡æ•°æ®
            scan_history = self.optimizer.code_quality_monitor.scan_history
            if not scan_history:
                return "âŒ æœªæ‰¾åˆ°ä»£ç è´¨é‡åˆ†ææ•°æ®ï¼Œè¯·å…ˆè¿è¡Œä»£ç è´¨é‡åˆ†æ"

            latest_scan = scan_history[-1]

            # æ”¶é›†å¯ä¿®å¤çš„é—®é¢˜
            issues_found = []
            code_smells = latest_scan.get("code_smells", {}).get("details", {})

            # BOMå­—ç¬¦å’Œéæ‰“å°å­—ç¬¦é—®é¢˜
            if not issue_types or "invalid_non_printable" in issue_types:
                issues_found.extend(self._collect_bom_issues())

            # å¼ƒç”¨çš„è½¬ä¹‰åºåˆ—
            if not issue_types or "deprecated_escape_sequence" in issue_types:
                issues_found.extend(self._collect_escape_sequence_issues())

            if not issues_found:
                return "âœ… æœªå‘ç°éœ€è¦ä¿®å¤çš„ä»£ç é—®é¢˜"

            if not auto_fix:
                # ä»…æ˜¾ç¤ºé—®é¢˜ï¼Œä¸è‡ªåŠ¨ä¿®å¤
                result = f"ğŸ” æ£€æµ‹åˆ° {len(issues_found)} ä¸ªä»£ç é—®é¢˜\n\n"

                for i, issue in enumerate(issues_found[:10], 1):
                    result += f"{i}. ã€{issue.get('severity', 'info')}ã€‘{issue.get('type', 'unknown')}\n"
                    result += f"   æ–‡ä»¶: {issue.get('file', 'unknown')}\n"
                    if issue.get('line'):
                        result += f"   è¡Œå·: {issue.get('line', 'unknown')}\n"
                    result += f"   æè¿°: {issue.get('description', 'unknown')}\n\n"

                if len(issues_found) > 10:
                    result += f"... è¿˜æœ‰ {len(issues_found) - 10} ä¸ªé—®é¢˜æœªæ˜¾ç¤º\n\n"

                result += "ğŸ’¡ æç¤º: ä½¿ç”¨å‚æ•° auto_fix=true å¯å°è¯•è‡ªåŠ¨ä¿®å¤é—®é¢˜ï¼ˆä¼šè‡ªåŠ¨å¤‡ä»½ï¼‰"
                return result

            # è‡ªåŠ¨ä¿®å¤æ¨¡å¼ - å¸¦å¤‡ä»½å’Œå›æ»š
            result = f"ğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤ä»£ç é—®é¢˜...\n"
            result += f"ğŸ“ å°†è‡ªåŠ¨å¤‡ä»½ä¿®æ”¹çš„æ–‡ä»¶\n"

            backup_dir = self._create_backup_dir()
            backups = []
            fixed_count = 0
            failed_issues = []

            for issue in issues_found:
                try:
                    issue_type = issue.get("type", "")
                    file_path = issue.get("file")
                    line_num = issue.get("line")

                    # åˆ›å»ºæ–‡ä»¶å¤‡ä»½
                    if file_path and Path(file_path).exists():
                        backup_path = self._backup_file(file_path, backup_dir)
                        backups.append({
                            "original": file_path,
                            "backup": backup_path,
                            "issue": issue
                        })

                    # ä¿®å¤é€»è¾‘
                    if issue_type == "deprecated_escape_sequence":
                        if file_path and line_num:
                            await self._fix_escape_sequence(file_path, line_num)
                            fixed_count += 1
                            result += f"âœ… ä¿®å¤: {file_path}:{line_num} - {issue.get('description', '')}\n"

                    elif issue_type == "invalid_non_printable":
                        if file_path:
                            await self._fix_non_printable(file_path)
                            fixed_count += 1
                            result += f"âœ… ä¿®å¤: {file_path} - ç§»é™¤æ— æ•ˆå­—ç¬¦\n"

                except Exception as e:
                    logger.warning(f"ä¿®å¤é—®é¢˜å¤±è´¥: {e}")
                    failed_issues.append(issue)
                    result += f"âŒ ä¿®å¤å¤±è´¥: {issue.get('description', '')} - {str(e)}\n"

            # éªŒè¯ä¿®å¤
            if backups:
                validation_errors = await self._validate_fixes(backups)

                if validation_errors:
                    result += f"\nâš ï¸  éªŒè¯å‘ç° {len(validation_errors)} ä¸ªé—®é¢˜ï¼Œæ­£åœ¨å›æ»š...\n"
                    rollback_count = await self._rollback_backups([b["backup"] for b in backups])
                    result += f"ğŸ”„ å·²å›æ»š {rollback_count} ä¸ªæ–‡ä»¶\n"
                    result += f"\nâŒ ä¿®å¤å¤±è´¥ï¼Œå·²æ¢å¤åŸå§‹çŠ¶æ€"
                    return result

            result += f"\nğŸ‰ ä¿®å¤å®Œæˆ: å…±ä¿®å¤ {fixed_count}/{len(issues_found)} ä¸ªé—®é¢˜"
            result += f"\nğŸ“¦ å¤‡ä»½ä½ç½®: {backup_dir}"

            if failed_issues:
                result += f"\nâš ï¸ éƒ¨åˆ†é—®é¢˜ä¿®å¤å¤±è´¥ ({len(failed_issues)} ä¸ª)"

            return result

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] ä»£ç ä¿®å¤å¤±è´¥: {e}", exc_info=True)
            return f"ä»£ç ä¿®å¤å¤±è´¥: {str(e)}"

    async def _fix_escape_sequence(self, file_path: str, line_num: int):
        """ä¿®å¤è½¬ä¹‰åºåˆ—é—®é¢˜"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            if line_num <= len(lines):
                line = lines[line_num - 1]

                # æ™ºèƒ½ä¿®å¤è½¬ä¹‰åºåˆ—é—®é¢˜
                # åªä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ä¸­çš„è½¬ä¹‰åºåˆ—
                if 're\\.' in line or 're\\s' in line or 're\\.' in line:
                    # è¿™å¯èƒ½æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œä¸åšä¿®æ”¹
                    return

                # ä¿®å¤å¸¸è§çš„å­—ç¬¦ä¸²è½¬ä¹‰åºåˆ—é—®é¢˜
                # r'\.' åœ¨æ™®é€šå­—ç¬¦ä¸²ä¸­åº”æ›¿æ¢ä¸º '\\\\.' è¡¨ç¤ºå­—é¢æ„æ€çš„åæ–œæ åŠ ç‚¹
                # ä½†åœ¨æ­£åˆ™è¡¨è¾¾å¼ä¸­åº”è¯¥æ˜¯æ­£ç¡®çš„

                # åªä¿®å¤æ˜æ˜¾çš„é—®é¢˜ï¼šåœ¨éåŸå§‹å­—ç¬¦ä¸²ä¸­ä½¿ç”¨éœ€è¦è½¬ä¹‰çš„å­—ç¬¦
                    if r'\.' in line and 'r"' not in line and "r'" not in line:
                        # æ£€æŸ¥æ˜¯å¦åœ¨æ­£åˆ™è¡¨è¾¾å¼ä¸Šä¸‹æ–‡ä¸­
                        if 're\\.' in line or 're\\s' in line or 're\\.' in line or 're\\s' in line:
                            # æ­£åˆ™è¡¨è¾¾å¼ä¸Šä¸‹æ–‡ï¼Œä¿æŒä¸å˜
                            pass
                        else:
                            # å¯èƒ½æ˜¯é”™è¯¯çš„è½¬ä¹‰ï¼Œä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²
                            if r'"\."' in line or r"'\.'" in line:
                                # å°† "\." è½¬æ¢ä¸º r"\."
                                fixed_line = line.replace(r'\.', r'\\.')
                                lines[line_num - 1] = fixed_line

                if r'\s' in line and 'r"' not in line and "r'" not in line:
                    if r'"\s"' in line or r"'\s'" in line:
                        # å°† "\s" è½¬æ¢ä¸º r"\s"
                        fixed_line = line.replace(r'\s', r'\\s')
                        lines[line_num - 1] = fixed_line

                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)

        except Exception as e:
            logger.warning(f"ä¿®å¤è½¬ä¹‰åºåˆ—å¤±è´¥ {file_path}:{line_num}: {e}")
            raise

    async def _fix_non_printable(self, file_path: str):
        """ç§»é™¤æ–‡ä»¶å¼€å¤´çš„BOMå­—ç¬¦"""
        try:
            with open(file_path, 'rb') as f:
                content = f.read()

            # æ£€æŸ¥å¹¶ç§»é™¤UTF-8 BOM
            if content.startswith(b'\xef\xbb\xbf'):
                content = content[3:]
                with open(file_path, 'wb') as f:
                    f.write(content)
                logger.info(f"å·²ç§»é™¤BOMå­—ç¬¦: {file_path}")

        except Exception as e:
            logger.warning(f"ç§»é™¤éæ‰“å°å­—ç¬¦å¤±è´¥ {file_path}: {e}")
            raise

    def _collect_bom_issues(self) -> List[Dict[str, Any]]:
        """æ”¶é›†BOMå­—ç¬¦å’Œéæ‰“å°å­—ç¬¦é—®é¢˜"""
        issues = []
        project_root = Path.cwd()

        for py_file in project_root.rglob("*.py"):
            if "venv" in str(py_file) or "__pycache__" in str(py_file):
                continue

            try:
                with open(py_file, 'rb') as f:
                    content = f.read()
                    if content.startswith(b'\xef\xbb\xbf'):
                        issues.append({
                            "type": "invalid_non_printable",
                            "severity": "medium",
                            "file": str(py_file),
                            "line": 1,
                            "description": "æ–‡ä»¶åŒ…å«UTF-8 BOMå­—ç¬¦"
                        })
            except Exception:
                continue

        return issues

    def _collect_escape_sequence_issues(self) -> List[Dict[str, Any]]:
        """æ”¶é›†å¼ƒç”¨çš„è½¬ä¹‰åºåˆ—é—®é¢˜"""
        issues = []
        project_root = Path.cwd()

        for py_file in project_root.rglob("*.py"):
            if "venv" in str(py_file) or "__pycache__" in str(py_file):
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()

                for i, line in enumerate(lines, 1):
                    # æ£€æµ‹åŸå§‹å­—ç¬¦ä¸²ä¸­çš„è½¬ä¹‰åºåˆ—
                    if r'\.' in line and not line.strip().startswith('#'):
                        # ç¡®ä¿ä¸æ˜¯åœ¨åŸå§‹å­—ç¬¦ä¸²ä¸­
                        if not ('r"' in line or "r'" in line):
                            issues.append({
                                "type": "deprecated_escape_sequence",
                                "severity": "low",
                                "file": str(py_file),
                                "line": i,
                                "description": "å­—ç¬¦ä¸²ä¸­åŒ…å«å¯èƒ½çš„è½¬ä¹‰åºåˆ—é—®é¢˜"
                            })
            except Exception:
                continue

        return issues

    def _create_backup_dir(self) -> str:
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        backup_base = Path("logs") / "code_fix_backups"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = backup_base / timestamp
        backup_dir.mkdir(parents=True, exist_ok=True)
        return str(backup_dir)

    def _backup_file(self, file_path: str, backup_dir: str) -> str:
        """å¤‡ä»½æ–‡ä»¶"""
        file_path = Path(file_path)
        backup_path = Path(backup_dir) / file_path.name

        # å¦‚æœæ–‡ä»¶åå†²çªï¼Œæ·»åŠ æ•°å­—åç¼€
        counter = 1
        while backup_path.exists():
            stem = file_path.stem
            suffix = file_path.suffix
            backup_path = Path(backup_dir) / f"{stem}_{counter}{suffix}"
            counter += 1

        shutil.copy2(file_path, backup_path)

        # è®°å½•å¤‡ä»½æ˜ å°„
        self._record_backup_mapping(backup_dir, backup_path.name, str(file_path))

        logger.info(f"å·²å¤‡ä»½: {file_path} -> {backup_path}")
        return str(backup_path)

    def _record_backup_mapping(self, backup_dir: str, backup_name: str, original_path: str):
        """è®°å½•å¤‡ä»½æ˜ å°„å…³ç³»"""
        import json
        record_file = Path(backup_dir) / "backup_record.json"

        # è¯»å–ç°æœ‰è®°å½•
        if record_file.exists():
            try:
                with open(record_file, 'r', encoding='utf-8') as f:
                    records = json.load(f)
            except Exception:
                records = {}
        else:
            records = {}

        # æ›´æ–°è®°å½•
        records[backup_name] = original_path

        # å†™å…¥æ–‡ä»¶
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, indent=2, ensure_ascii=False)

    async def _validate_fixes(self, backups: List[Dict[str, Any]]) -> List[str]:
        """éªŒè¯ä¿®å¤åçš„æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        errors = []

        for backup_info in backups:
            original_path = backup_info["original"]

            try:
                with open(original_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # å°è¯•è§£æä¸ºæœ‰æ•ˆçš„Pythonä»£ç 
                ast.parse(content)

            except SyntaxError as e:
                errors.append(f"{original_path}: {e}")
                logger.error(f"éªŒè¯å¤±è´¥ {original_path}: {e}")
            except Exception as e:
                errors.append(f"{original_path}: {e}")
                logger.error(f"éªŒè¯å¤±è´¥ {original_path}: {e}")

        return errors

    async def _rollback_backups(self, backup_paths: List[str]) -> int:
        """å›æ»šå¤‡ä»½æ–‡ä»¶"""
        rollback_count = 0

        for backup_path in backup_paths:
            try:
                backup_path = Path(backup_path)
                original_path = backup_path.name

                # å°è¯•æŸ¥æ‰¾åŸå§‹æ–‡ä»¶ä½ç½®
                project_root = Path.cwd()
                for py_file in project_root.rglob(original_path):
                    # ä»å¤‡ä»½æ–‡ä»¶åä¸­ç§»é™¤æ•°å­—åç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    if "_" in py_file.stem:
                        original_name = py_file.stem.rsplit('_', 1)[0] + py_file.suffix
                        original_file = py_file.parent / original_name
                    else:
                        original_file = py_file

                    if original_file.exists():
                        shutil.copy2(backup_path, original_file)
                        rollback_count += 1
                        logger.info(f"å·²å›æ»š: {backup_path} -> {original_file}")

            except Exception as e:
                logger.warning(f"å›æ»šå¤±è´¥ {backup_path}: {e}")

        return rollback_count

    async def rollback_fixes(self, args: Dict[str, Any]) -> str:
        """æ‰‹åŠ¨å›æ»šä»£ç ä¿®å¤"""
        try:
            backup_dir = args.get("backup_dir")
            if not backup_dir:
                # è·å–æœ€æ–°çš„å¤‡ä»½ç›®å½•
                backup_base = Path("logs") / "code_fix_backups"
                if not backup_base.exists():
                    return "âŒ æœªæ‰¾åˆ°å¤‡ä»½ç›®å½•"

                backup_dirs = sorted(backup_base.glob("*"), key=lambda x: x.stat().st_mtime, reverse=True)
                if not backup_dirs:
                    return "âŒ æœªæ‰¾åˆ°ä»»ä½•å¤‡ä»½"

                backup_dir = str(backup_dirs[0])

            backup_path = Path(backup_dir)
            if not backup_path.exists():
                return f"âŒ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: {backup_dir}"

            # æŸ¥æ‰¾æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            backup_files = list(backup_path.glob("*.py"))
            if not backup_files:
                return f"âŒ å¤‡ä»½ç›®å½•ä¸­æ²¡æœ‰Pythonæ–‡ä»¶: {backup_dir}"

            result = f"ğŸ”„ å¼€å§‹å›æ»šä»£ç ä¿®å¤...\n"
            result += f"ğŸ“ å¤‡ä»½ç›®å½•: {backup_dir}\n"
            result += f"ğŸ“‹ æ‰¾åˆ° {len(backup_files)} ä¸ªå¤‡ä»½æ–‡ä»¶\n\n"

            rollback_count = 0
            failed_count = 0

            # è¯»å–å¤‡ä»½è®°å½•ä»¥è·å–åŸå§‹è·¯å¾„
            backup_record_file = backup_path / "backup_record.json"
            backup_map = {}
            if backup_record_file.exists():
                try:
                    import json
                    with open(backup_record_file, 'r', encoding='utf-8') as f:
                        backup_map = json.load(f)
                except Exception:
                    pass

            for backup_file in backup_files:
                try:
                    # ä½¿ç”¨å¤‡ä»½è®°å½•æŸ¥æ‰¾åŸå§‹è·¯å¾„
                    original_path = backup_map.get(backup_file.name)

                    if original_path and Path(original_path).exists():
                        shutil.copy2(backup_file, original_path)
                        rollback_count += 1
                        result += f"âœ… å·²å›æ»š: {original_path}\n"
                    else:
                        # å›é€€åˆ°åŸæ¥çš„æŸ¥æ‰¾é€»è¾‘ï¼Œä½†é™åˆ¶æŸ¥æ‰¾èŒƒå›´
                        project_root = Path.cwd()
                        found = False

                        # åªæŸ¥æ‰¾å‰å‡ çº§ç›®å½•ï¼Œé¿å…è¯¯åŒ¹é…
                        search_dirs = [
                            project_root / "system",
                            project_root / "ui" / "components",
                            project_root / "ui" / "utils",
                            project_root / "mcpserver",
                            project_root / "agentserver"
                        ]

                        for search_dir in search_dirs:
                            if not search_dir.exists():
                                continue

                            original_file = search_dir / backup_file.name
                            if original_file.exists():
                                shutil.copy2(backup_file, original_file)
                                rollback_count += 1
                                result += f"âœ… å·²å›æ»š: {original_file}\n"
                                found = True
                                break

                        if not found:
                            result += f"âš ï¸ æœªæ‰¾åˆ°åŸå§‹æ–‡ä»¶: {backup_file.name}\n"

                except Exception as e:
                    failed_count += 1
                    result += f"âŒ å›æ»šå¤±è´¥ {backup_file.name}: {e}\n"
                    logger.warning(f"å›æ»šå¤±è´¥ {backup_file}: {e}")

            result += f"\nğŸ‰ å›æ»šå®Œæˆ: {rollback_count}/{len(backup_files)} ä¸ªæ–‡ä»¶"

            if failed_count > 0:
                result += f"\nâš ï¸ {failed_count} ä¸ªæ–‡ä»¶å›æ»šå¤±è´¥"

            return result

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] å›æ»šå¤±è´¥: {e}", exc_info=True)
            return f"å›æ»šå¤±è´¥: {str(e)}"

    async def list_backups(self, args: Dict[str, Any]) -> str:
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
        try:
            backup_base = Path("logs") / "code_fix_backups"
            if not backup_base.exists():
                return "âŒ æœªæ‰¾åˆ°å¤‡ä»½ç›®å½•"

            backup_dirs = sorted(backup_base.glob("*"), key=lambda x: x.stat().st_mtime, reverse=True)

            if not backup_dirs:
                return "âŒ æœªæ‰¾åˆ°ä»»ä½•å¤‡ä»½"

            result = f"ğŸ“‚ ä»£ç ä¿®å¤å¤‡ä»½åˆ—è¡¨\n"
            result += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            result += f"å…±æ‰¾åˆ° {len(backup_dirs)} ä¸ªå¤‡ä»½\n\n"

            for i, backup_dir in enumerate(backup_dirs, 1):
                backup_files = list(backup_dir.glob("*.py"))
                mtime = datetime.fromtimestamp(backup_dir.stat().st_mtime)

                result += f"{i}. ğŸ“ {backup_dir.name}\n"
                result += f"   ğŸ“… åˆ›å»ºæ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\n"
                result += f"   ğŸ“„ æ–‡ä»¶æ•°: {len(backup_files)}\n"
                result += f"   ğŸ“ è·¯å¾„: {backup_dir}\n\n"

            return result.strip()

        except Exception as e:
            logger.error(f"[SelfOptimizationTools] åˆ—å‡ºå¤‡ä»½å¤±è´¥: {e}", exc_info=True)
            return f"åˆ—å‡ºå¤‡ä»½å¤±è´¥: {str(e)}"


# åˆ›å»ºå…¨å±€å·¥å…·å®ä¾‹
_tools_instance: Optional[SelfOptimizationTools] = None


def get_tools_instance() -> SelfOptimizationTools:
    """è·å–å·¥å…·å®ä¾‹"""
    global _tools_instance
    if _tools_instance is None:
        _tools_instance = SelfOptimizationTools()
    return _tools_instance


# å·¥å…·æ³¨å†Œè¡¨
TOOLS_REGISTRY = {
    "check_system_health": {
        "name": "check_system_health",
        "description": "æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼ŒåŒ…æ‹¬CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨ç‡å’Œå„æœåŠ¡çŠ¶æ€",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "analyze_performance": {
        "name": "analyze_performance",
        "description": "åˆ†æç³»ç»Ÿæ€§èƒ½ï¼ŒåŒ…æ‹¬å„æ“ä½œçš„è€—æ—¶ã€è°ƒç”¨æ¬¡æ•°å’Œé”™è¯¯ç‡",
        "parameters": {
            "type": "object",
            "properties": {
                "operation_name": {
                    "type": "string",
                    "description": "æŒ‡å®šè¦åˆ†æçš„æ“ä½œåç§°ï¼Œä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰æ“ä½œ"
                }
            }
        }
    },
    "run_optimization": {
        "name": "run_optimization",
        "description": "è¿è¡Œè‡ªåŠ¨ä¼˜åŒ–ï¼ŒåŸºäºå¥åº·æ£€æŸ¥å’Œæ€§èƒ½åˆ†æç»“æœè‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "analyze_code_quality": {
        "name": "analyze_code_quality",
        "description": "åˆ†æä»£ç è´¨é‡ï¼Œæ£€æµ‹å¤æ‚åº¦ã€é‡å¤ä»£ç ã€ä»£ç å¼‚å‘³ç­‰é—®é¢˜",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "export_reports": {
        "name": "export_reports",
        "description": "å¯¼å‡ºæ‰€æœ‰åˆ†ææŠ¥å‘Šåˆ°logsç›®å½•",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "get_status": {
        "name": "get_status",
        "description": "è·å–è‡ªæˆ‘ä¼˜åŒ–ç³»ç»Ÿçš„è¿è¡ŒçŠ¶æ€",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    },
    "fix_code_issues": {
        "name": "fix_code_issues",
        "description": "ä¿®å¤æ£€æµ‹åˆ°çš„ä»£ç é—®é¢˜ï¼Œæ”¯æŒè‡ªåŠ¨ä¿®å¤BOMå­—ç¬¦ã€è½¬ä¹‰åºåˆ—ç­‰é—®é¢˜ï¼Œä¼šè‡ªåŠ¨å¤‡ä»½æ–‡ä»¶å¹¶åœ¨ä¿®å¤å¤±è´¥æ—¶è‡ªåŠ¨å›æ»š",
        "parameters": {
            "type": "object",
            "properties": {
                "auto_fix": {
                    "type": "boolean",
                    "description": "æ˜¯å¦è‡ªåŠ¨ä¿®å¤é—®é¢˜ï¼Œfalseæ—¶ä»…æ˜¾ç¤ºé—®é¢˜åˆ—è¡¨"
                },
                "issue_types": {
                    "type": "array",
                    "description": "æŒ‡å®šè¦ä¿®å¤çš„é—®é¢˜ç±»å‹ï¼Œå¦‚['deprecated_escape_sequence', 'invalid_non_printable']"
                }
            }
        }
    },
    "rollback_fixes": {
        "name": "rollback_fixes",
        "description": "æ‰‹åŠ¨å›æ»šä»£ç ä¿®å¤ï¼Œä»å¤‡ä»½æ¢å¤æ–‡ä»¶",
        "parameters": {
            "type": "object",
            "properties": {
                "backup_dir": {
                    "type": "string",
                    "description": "æŒ‡å®šè¦å›æ»šçš„å¤‡ä»½ç›®å½•è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™å›æ»šæœ€æ–°çš„å¤‡ä»½"
                }
            }
        }
    },
    "list_backups": {
        "name": "list_backups",
        "description": "åˆ—å‡ºæ‰€æœ‰ä»£ç ä¿®å¤å¤‡ä»½",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    }
}


async def call_tool(tool_name: str, args: Dict[str, Any]) -> str:
    """
    è°ƒç”¨è‡ªæˆ‘ä¼˜åŒ–å·¥å…·

    Args:
        tool_name: å·¥å…·åç§°
        args: å·¥å…·å‚æ•°

    Returns:
        å·¥å…·æ‰§è¡Œç»“æœ
    """
    tools = get_tools_instance()

    tool_methods = {
        "check_system_health": tools.check_system_health,
        "analyze_performance": tools.analyze_performance,
        "run_optimization": tools.run_optimization,
        "analyze_code_quality": tools.analyze_code_quality,
        "export_reports": tools.export_reports,
        "get_status": tools.get_status,
        "fix_code_issues": tools.fix_code_issues,
        "rollback_fixes": tools.rollback_fixes,
        "list_backups": tools.list_backups
    }

    method = tool_methods.get(tool_name)
    if method is None:
        return f"æœªçŸ¥å·¥å…·: {tool_name}"

    return await method(args)
