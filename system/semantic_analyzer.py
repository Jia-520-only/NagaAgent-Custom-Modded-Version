#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½è¯­æ„åˆ†æå™¨ - æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡æ™ºèƒ½åˆ¤æ–­ï¼š
1. æ˜¯å¦éœ€è¦è°ƒç”¨MCPå·¥å…·
2. è¾“å‡ºåº”è¯¥ç”¨é•¿æ–‡æœ¬è¿˜æ˜¯çŸ­æ–‡æœ¬
3. ä½¿ç”¨ä»€ä¹ˆå›å¤é£æ ¼ï¼ˆç®€æ´/è¯¦ç»†/æƒ…æ„Ÿï¼‰
"""

import re
import json
from typing import Dict, Any, Optional, List
from dataclasses import dataclass


@dataclass
class SemanticAnalysis:
    """è¯­æ„åˆ†æç»“æœ"""
    # æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    need_tool_call: bool = False
    # å»ºè®®çš„è¾“å‡ºæ¨¡å¼: "short" (ç®€æ´), "long" (è¯¦ç»†), "normal" (æ­£å¸¸)
    output_mode: str = "normal"
    # å»ºè®®çš„å›å¤é£æ ¼: "concise" (ç®€æ´), "detailed" (è¯¦ç»†), "emotional" (æƒ…æ„Ÿ), "helpful" (å¸®åŠ©)
    reply_style: str = "helpful"
    # æ£€æµ‹åˆ°çš„æ„å›¾å…³é”®è¯
    intent_keywords: List[str] = None
    # ç½®ä¿¡åº¦ 0-1
    confidence: float = 0.0

    def __post_init__(self):
        if self.intent_keywords is None:
            self.intent_keywords = []


class SemanticAnalyzer:
    """æ™ºèƒ½è¯­æ„åˆ†æå™¨"""

    # å·¥å…·è°ƒç”¨å…³é”®è¯æ˜ å°„
    TOOL_KEYWORDS = {
        "å¤©æ°”": ["å¤©æ°”", "æ°”æ¸©", "æ¸©åº¦", "é™é›¨", "æ™´æœ—", "é˜´å¤©", "forecast"],
        "æ—¶é—´": ["å‡ ç‚¹", "ç°åœ¨", "æ—¥æœŸ", "æ˜ŸæœŸ", "å‘¨å‡ ", "æ—¶é—´"],
        "æœç´¢": ["æœç´¢", "æŸ¥è¯¢", "æ‰¾ä¸€ä¸‹", "çœ‹çœ‹æœ‰æ²¡æœ‰", "æ˜¯ä»€ä¹ˆ", "ç™¾åº¦"],
        "å¯åŠ¨åº”ç”¨": ["æ‰“å¼€", "å¯åŠ¨", "è¿è¡Œ", "å¼€å¯", "exec", "launch"],
        "ç»˜å›¾": ["ç”»", "ç”Ÿæˆå›¾ç‰‡", "ç”»å›¾", "å›¾åƒ", "ç»˜ç”»", "ç”Ÿæˆä¸€å¼ "],
        "ç½‘é¡µè§£æ": ["è§£æ", "çˆ¬å–", "æå–", "åˆ†æç½‘é¡µ", "get"],
        "è§†é¢‘": ["è§†é¢‘", "æ’­æ”¾", "bç«™", "bilibili", "youtube"],
        "éŸ³ä¹": ["éŸ³ä¹", "æ­Œæ›²", "å¬æ­Œ", "æ’­æ”¾éŸ³ä¹", "singer"],
        "ç³»ç»Ÿæ§åˆ¶": ["æ¸…ç†", "ä¼˜åŒ–", "é‡å¯", "å…³æœº", "å‘½ä»¤", "cmd"],
        "è®°å¿†": ["è®°ä½", "å­˜å‚¨", "å¤‡å¿˜", "æé†’", "note"],
    }

    # çŸ­æ–‡æœ¬å…³é”®è¯ï¼ˆéœ€è¦ç®€æ´å›å¤ï¼‰
    SHORT_RESPONSE_KEYWORDS = [
        "æ˜¯", "å¦", "å¥½", "è¡Œ", "ok", "æ˜¯çš„", "å¯¹çš„", "æ²¡é—®é¢˜",
        "å¤šè°¢", "è°¢è°¢", "æ™šå®‰", "æ—©å®‰", "å†è§", "æ‹œæ‹œ",
        "å‡ ", "å¤šå°‘", "ä»€ä¹ˆæ—¶å€™", "åœ¨å“ª", "å“ªé‡Œ",
        "ä¸ºä»€ä¹ˆ", "ä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•"
    ]

    # é•¿æ–‡æœ¬å…³é”®è¯ï¼ˆéœ€è¦è¯¦ç»†å›å¤ï¼‰
    LONG_RESPONSE_KEYWORDS = [
        "è§£é‡Š", "è¯´æ˜", "ä»‹ç»", "åˆ†æ", "è¯¦ç»†", "è¯¦ç»†ç‚¹",
        "åŸç†", "æ­¥éª¤", "æ•™ç¨‹", "æŒ‡å—", "æ–¹æ³•", "æ–¹æ³•",
        "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆåŠ", "æ€ä¹ˆè§£å†³", "å¦‚ä½•å¤„ç†",
        "æ•…äº‹", "ç»å†", "æ„Ÿå—", "æƒ³æ³•", "å»ºè®®"
    ]

    # æƒ…æ„Ÿäº¤æµå…³é”®è¯ï¼ˆéœ€è¦æƒ…æ„ŸåŒ–å›å¤ï¼‰
    EMOTIONAL_KEYWORDS = [
        "å–œæ¬¢", "çˆ±", "è®¨åŒ", "è®¨åŒ", "å¼€å¿ƒ", "éš¾è¿‡",
        "ç”Ÿæ°”", "æ‹…å¿ƒ", "å®³æ€•", "ç´§å¼ ", "æ”¾æ¾",
        "å­¤ç‹¬", "å¯‚å¯", "å¹¸ç¦", "ç—›è‹¦", "ç´¯",
        "å®‰æ…°", "æ‹¥æŠ±", "é¼“åŠ±", "æ”¯æŒ", "é™ªä¼´"
    ]

    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        pass

    def analyze(self, message: str, conversation_history: List[Dict[str, str]] = None) -> SemanticAnalysis:
        """
        åˆ†ææ¶ˆæ¯çš„è¯­æ„

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰

        Returns:
            SemanticAnalysis: åˆ†æç»“æœ
        """
        analysis = SemanticAnalysis()

        # 1. æ£€æµ‹æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
        analysis.need_tool_call, analysis.intent_keywords = self._detect_tool_intent(message)
        if analysis.need_tool_call:
            analysis.confidence = 0.8
            return analysis

        # 2. æ£€æµ‹è¾“å‡ºæ¨¡å¼ï¼ˆçŸ­æ–‡æœ¬/é•¿æ–‡æœ¬/æ­£å¸¸ï¼‰
        analysis.output_mode = self._detect_output_mode(message)

        # 3. æ£€æµ‹å›å¤é£æ ¼
        analysis.reply_style = self._detect_reply_style(message, analysis.output_mode)

        # 4. è®¡ç®—ç½®ä¿¡åº¦
        analysis.confidence = self._calculate_confidence(message, analysis)

        return analysis

    def _detect_tool_intent(self, message: str) -> tuple:
        """
        æ£€æµ‹æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·

        Returns:
            (æ˜¯å¦éœ€è¦å·¥å…·, åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨)
        """
        message_lower = message.lower()
        matched_keywords = []

        for tool_name, keywords in self.TOOL_KEYWORDS.items():
            for keyword in keywords:
                if keyword.lower() in message_lower:
                    matched_keywords.append(f"{tool_name}:{keyword}")

        if matched_keywords:
            return True, matched_keywords

        return False, []

    def _detect_output_mode(self, message: str) -> str:
        """
        æ£€æµ‹è¾“å‡ºæ¨¡å¼

        Returns:
            "short", "long", or "normal"
        """
        message_lower = message.lower()

        # æ£€æŸ¥æ˜¯å¦ä¸ºç®€å•é—®é¢˜ï¼ˆçŸ­æ–‡æœ¬ï¼‰
        for keyword in self.SHORT_RESPONSE_KEYWORDS:
            if keyword in message_lower:
                # æ’é™¤"ä¸ºä»€ä¹ˆ"è¿™ç§éœ€è¦è¯¦ç»†è§£é‡Šçš„è¯
                if "ä¸ºä»€ä¹ˆ" not in message:
                    return "short"

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¯¦ç»†è§£é‡Šï¼ˆé•¿æ–‡æœ¬ï¼‰
        for keyword in self.LONG_RESPONSE_KEYWORDS:
            if keyword in message_lower:
                return "long"

        return "normal"

    def _detect_reply_style(self, message: str, output_mode: str) -> str:
        """
        æ£€æµ‹å›å¤é£æ ¼

        Returns:
            "concise", "detailed", "emotional", or "helpful"
        """
        message_lower = message.lower()

        # æ£€æŸ¥æƒ…æ„Ÿäº¤æµ
        for keyword in self.EMOTIONAL_KEYWORDS:
            if keyword in message_lower:
                return "emotional"

        # æ ¹æ®è¾“å‡ºæ¨¡å¼è¿”å›é£æ ¼
        if output_mode == "short":
            return "concise"
        elif output_mode == "long":
            return "detailed"

        return "helpful"

    def _calculate_confidence(self, message: str, analysis: SemanticAnalysis) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        confidence = 0.5  # é»˜è®¤ç½®ä¿¡åº¦

        # å¦‚æœæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨æ„å›¾ï¼Œç½®ä¿¡åº¦è¾ƒé«˜
        if analysis.need_tool_call:
            confidence = 0.8
        # å¦‚æœæ£€æµ‹åˆ°æƒ…æ„Ÿå…³é”®è¯ï¼Œç½®ä¿¡åº¦ä¸­ç­‰
        elif analysis.reply_style == "emotional":
            confidence = 0.7
        # å¦‚æœè¾“å‡ºæ¨¡å¼æ˜ç¡®ï¼Œç½®ä¿¡åº¦ä¸­ç­‰
        elif analysis.output_mode in ["short", "long"]:
            confidence = 0.6

        return confidence

    def format_analysis_as_text(self, analysis: SemanticAnalysis) -> str:
        """
        å°†åˆ†æç»“æœæ ¼å¼åŒ–ä¸ºæ–‡æœ¬ï¼ˆç”¨äºè°ƒè¯•ï¼‰

        Args:
            analysis: åˆ†æç»“æœ

        Returns:
            æ ¼å¼åŒ–æ–‡æœ¬
        """
        lines = [
            f"ğŸ” è¯­æ„åˆ†æç»“æœ:",
            f"   - å·¥å…·è°ƒç”¨: {'æ˜¯' if analysis.need_tool_call else 'å¦'}",
            f"   - è¾“å‡ºæ¨¡å¼: {analysis.output_mode}",
            f"   - å›å¤é£æ ¼: {analysis.reply_style}",
            f"   - æ„å›¾å…³é”®è¯: {', '.join(analysis.intent_keywords) if analysis.intent_keywords else 'æ— '}",
            f"   - ç½®ä¿¡åº¦: {analysis.confidence:.2f}"
        ]
        return "\n".join(lines)


# å•ä¾‹æ¨¡å¼
_analyzer_instance: Optional[SemanticAnalyzer] = None


def get_semantic_analyzer() -> SemanticAnalyzer:
    """è·å–è¯­ä¹‰åˆ†æå™¨å•ä¾‹"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = SemanticAnalyzer()
    return _analyzer_instance
